{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1cDMWdOjJ2r"
   },
   "source": [
    "This notebook (and the slides from lecture 8) will help you go straight from training a model in Colab to deploying it in a webpage with TensorFlow.js - without having to leave the browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "248xIjNGCRU0"
   },
   "source": [
    "Configure this notebook to work with your GitHub account by populating these fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ft9uEY7UCH46"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g4k9_Ke9CaOq"
   },
   "outputs": [],
   "source": [
    "# your github username\n",
    "USER_NAME = \"pinhao1994\"\n",
    "\n",
    "# the email associated with your commits\n",
    "# (may not matter if you leave it as this)\n",
    "USER_EMAIL = \"pinhao1994@gmail.com\"\n",
    "\n",
    "# the user token you've created (see the lecture 8 slides for instructions)\n",
    "TOKEN = open(\"acctoken.txt\", \"r\").read() \n",
    "\n",
    "# site name\n",
    "# for example, if my user_name is \"foo\", then this notebook will create\n",
    "# a site at https://foo.github.io/hw4/\n",
    "SITE_NAME = \"ADL/a4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dnPqmO8vDDwW"
   },
   "source": [
    "Next, run this cell to configure git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q0IMoqVdCIb4"
   },
   "outputs": [],
   "source": [
    "!git config --global user.email {USER_NAME}\n",
    "!git config --global user.name  {USER_EMAIL}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XYfDxuMfDVas"
   },
   "source": [
    "Clone your GitHub pages repo (see the lecture 8 slides for instructions on how to create one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qRUyZiFqDUxt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "repo_path = USER_NAME + '.github.io'\n",
    "if not os.path.exists(os.path.join(os.getcwd(), repo_path)):\n",
    "  !git clone https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{USER_NAME}.github.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qu4OA27iDU0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(repo_path)\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KgISB_cAHPIs"
   },
   "source": [
    "Create a folder for your site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAA6t4slF0nB"
   },
   "outputs": [],
   "source": [
    "project_path = os.path.join(os.getcwd(), SITE_NAME)\n",
    "if not os.path.exists(project_path): \n",
    "  os.mkdir(project_path)\n",
    "os.chdir(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DwYh8sXKHs3O"
   },
   "source": [
    "These paths will be used by the converter script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ABggwdWMGe2h"
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY\n",
    "MODEL_DIR = os.path.join(project_path, \"model_js\")\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "  os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJpu2BkSUWe4"
   },
   "source": [
    "As an example, we will create and vectorize a few documents. (Check out https://www.gutenberg.org/ for a bunch of free e-books.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pgm8y7fWHxOI"
   },
   "outputs": [],
   "source": [
    "# A few snippets from Alice in Wonderland\n",
    "ex1 = \"Alice was beginning to get very tired of sitting by her sister on the bank.\"\n",
    "ex2 = \"Once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it.\"\n",
    "\n",
    "# Dracula\n",
    "ex3 = \"Buda-Pesth seems a wonderful place.\"\n",
    "ex4 = \"Left Munich at 8:35 P. M., on 1st May, arriving at Vienna early next morning.\"\n",
    "\n",
    "# Illiad\n",
    "ex5 = \"Scepticism was as much the result of knowledge, as knowledge is of scepticism.\"\n",
    "ex6 = \"To be content with what we at present know, is, for the most part, to shut our ears against conviction.\"\n",
    "\n",
    "# A Surgeon in Arms\n",
    "ex7 = 'Life \"out there\" is so strange, so unique, so full of hardship and danger, and' \\\n",
    "    'yet so intensely interesting that it seems like another world.'  \n",
    "ex8 = 'It is a different life from any other that is to be found in our world today.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CASpAIgJalTp"
   },
   "outputs": [],
   "source": [
    "x_train = [ex1, ex2, ex3, ex4, ex5, ex6, ex7, ex8]\n",
    "y_train = [0, 0, 1, 1, 2, 2, 3, 3] # Indicating which book each sentence is from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CVfStwZCYBAq"
   },
   "source": [
    "Tokenize the documents, create a word index (word -> number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HOHTxREVQalF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "max_len = 20\n",
    "num_words = 1000\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# Fit the tokenizer on the training data\n",
    "t = Tokenizer(num_words=num_words)\n",
    "t.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqyqHuLwWT-Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is': 1, 'to': 2, 'of': 3, 'the': 4, 'it': 5, 'so': 6, 'was': 7, 'at': 8, 'her': 9, 'sister': 10, 'on': 11, 'or': 12, 'had': 13, 'in': 14, 'seems': 15, 'a': 16, 'scepticism': 17, 'as': 18, 'knowledge': 19, 'be': 20, 'our': 21, 'life': 22, 'that': 23, 'world': 24, 'alice': 25, 'beginning': 26, 'get': 27, 'very': 28, 'tired': 29, 'sitting': 30, 'by': 31, 'bank': 32, 'once': 33, 'twice': 34, 'she': 35, 'peeped': 36, 'into': 37, 'book': 38, 'reading': 39, 'but': 40, 'no': 41, 'pictures': 42, 'conversations': 43, 'buda': 44, 'pesth': 45, 'wonderful': 46, 'place': 47, 'left': 48, 'munich': 49, '8': 50, '35': 51, 'p': 52, 'm': 53, '1st': 54, 'may': 55, 'arriving': 56, 'vienna': 57, 'early': 58, 'next': 59, 'morning': 60, 'much': 61, 'result': 62, 'content': 63, 'with': 64, 'what': 65, 'we': 66, 'present': 67, 'know': 68, 'for': 69, 'most': 70, 'part': 71, 'shut': 72, 'ears': 73, 'against': 74, 'conviction': 75, 'out': 76, 'there': 77, 'strange': 78, 'unique': 79, 'full': 80, 'hardship': 81, 'and': 82, 'danger': 83, 'andyet': 84, 'intensely': 85, 'interesting': 86, 'like': 87, 'another': 88, 'different': 89, 'from': 90, 'any': 91, 'other': 92, 'found': 93, 'today': 94}\n"
     ]
    }
   ],
   "source": [
    "print(t.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "feIAyrrxYFoU"
   },
   "source": [
    "Here's how we vectorize a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jfi7tJbHTwIc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25, 7, 26, 2, 27, 28, 29, 3, 30, 31, 9, 10, 11, 4, 32]]\n"
     ]
    }
   ],
   "source": [
    "vectorized = t.texts_to_sequences([ex1])\n",
    "print(vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vUfL6MVhYHof"
   },
   "source": [
    "Apply padding if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rbghRbY5QaMV"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "padded = pad_sequences(vectorized, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9xwd6ND_UIKk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  7 26  2 27 28 29  3 30 31  9 10 11  4 32  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C9NUXTTuYLZ0"
   },
   "source": [
    "We will save the word index in metadata. Later, we'll use it to convert words typed in the browser to numbers for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UpzusXHhULBr"
   },
   "outputs": [],
   "source": [
    "metadata = {\n",
    "  'word_index': t.word_index,\n",
    "  'max_len': max_len,\n",
    "  'vocabulary_size': num_words,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l57eA3ApZGsC"
   },
   "source": [
    "Define a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oLQeTh3uVqtj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 20, 8)             8000      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 644       \n",
      "=================================================================\n",
      "Total params: 8,644\n",
      "Trainable params: 8,644\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 8\n",
    "n_classes = 4\n",
    "epochs = 10\n",
    "\n",
    "import keras\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(num_words, embedding_size, input_shape=(max_len,)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_classes, activation='softmax'))\n",
    "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6VOtCRJiYWZZ"
   },
   "source": [
    "Prepare some training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Q8Y1ZuZYYKC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  7 26  2 27 28 29  3 30 31  9 10 11  4 32  0  0  0  0  0]\n",
      " [34 35 13 36 37  4 38  9 10  7 39 40  5 13 41 42 12 43 14  5]\n",
      " [44 45 15 16 46 47  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [48 49  8 50 51 52 53 11 54 55 56  8 57 58 59 60  0  0  0  0]\n",
      " [17  7 18 61  4 62  3 19 18 19  1  3 17  0  0  0  0  0  0  0]\n",
      " [ 2 20 63 64 65 66  8 67 68  1 69  4 70 71  2 72 21 73 74 75]\n",
      " [ 6 78  6 79  6 80  3 81 82 83 84  6 85 86 23  5 15 87 88 24]\n",
      " [ 5  1 16 89 22 90 91 92 23  1  2 20 93 14 21 24 94  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "x_train = t.texts_to_sequences(x_train)\n",
    "x_train = pad_sequences(x_train, maxlen=max_len, padding='post')\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VUWlD3jiX10c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3906 - acc: 0.2500\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 213us/step - loss: 1.3826 - acc: 0.3750\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 221us/step - loss: 1.3720 - acc: 0.6250\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 318us/step - loss: 1.3613 - acc: 0.7500\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 268us/step - loss: 1.3508 - acc: 0.7500\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 260us/step - loss: 1.3402 - acc: 0.7500\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 222us/step - loss: 1.3297 - acc: 0.7500\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 278us/step - loss: 1.3191 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 217us/step - loss: 1.3086 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 265us/step - loss: 1.2980 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12770dd68>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y1YbPNWIenE5"
   },
   "source": [
    "Demo using the model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcmpKvKUY_hK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48 49  8 50 51 52 53 11 54 55 56  8 57 58 59 60  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "test_example = \"Left Munich at 8:35 P. M., on 1st May, arriving at Vienna early next morning.\"\n",
    "x_test = t.texts_to_sequences([test_example])\n",
    "x_test = pad_sequences(x_test, maxlen=max_len, padding='post')\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y9dsZSQnrqoU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25315917 0.26761693 0.2397365  0.2394874 ]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x_test)\n",
    "print(preds)\n",
    "import numpy as np\n",
    "print(np.argmax(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G-Kuwvqcfptq"
   },
   "source": [
    "Convert the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nyo2Q_ehe2RT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved model artifcats in directory: /Users/apple/Dropbox/Billy/ADL/HW4/pinhao1994.github.io/ADL/a4/model_js\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "metadata_json_path = os.path.join(MODEL_DIR, 'metadata.json')\n",
    "json.dump(metadata, open(metadata_json_path, 'wt'))\n",
    "tfjs.converters.save_keras_model(model, MODEL_DIR)\n",
    "print('\\nSaved model artifcats in directory: %s' % MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z609mw1aj-RJ"
   },
   "source": [
    "Write an index.html and an index.js file configured to load our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IoFAxt8nj9fp"
   },
   "outputs": [],
   "source": [
    "index_html = \"\"\"\n",
    "<!doctype html>\n",
    "\n",
    "<body>\n",
    "  <style>\n",
    "    #textfield {\n",
    "      font-size: 120%;\n",
    "      width: 60%;\n",
    "      height: 200px;\n",
    "    }\n",
    "  </style>\n",
    "  <h1>\n",
    "    Pin-Hao Chen ADL HW4 Part1 DEMO\n",
    "  </h1>\n",
    "  <hr>\n",
    "  <div class=\"create-model\">\n",
    "    <button id=\"load-model\" style=\"display:none\">Load model</button>\n",
    "  </div>\n",
    "  <div>\n",
    "    <div>\n",
    "      <span>Vocabulary size: </span>\n",
    "      <span id=\"vocabularySize\"></span>\n",
    "    </div>\n",
    "    <div>\n",
    "      <span>Max length: </span>\n",
    "      <span id=\"maxLen\"></span>\n",
    "    </div>\n",
    "  </div>\n",
    "  <hr>\n",
    "  <div>\n",
    "    <select id=\"example-select\" class=\"form-control\">\n",
    "      <option value=\"example1\">Alice's Adventures in Wonderland</option>\n",
    "      <option value=\"example2\">Dracula</option>\n",
    "      <option value=\"example3\">The Iliad</option>\n",
    "      <option value=\"example4\">A Surgeon in Arms</option>\n",
    "    </select>\n",
    "  </div>\n",
    "  <div>\n",
    "    <textarea id=\"text-entry\"></textarea>\n",
    "  </div>\n",
    "  <hr>\n",
    "  <div>\n",
    "    <span id=\"status\">Standing by.</span>\n",
    "  </div>\n",
    "\n",
    "  <script src='https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js'></script>\n",
    "  <script src='index.js'></script>\n",
    "</body>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-JsQLbLnkhhk"
   },
   "outputs": [],
   "source": [
    "index_js = \"\"\"\n",
    "const HOSTED_URLS = {\n",
    "  model:\n",
    "      'model_js/model.json',\n",
    "  metadata:\n",
    "      'model_js/metadata.json'\n",
    "};\n",
    "\n",
    "const examples = {\n",
    "  'example1':\n",
    "      'Alice was beginning to get very tired of sitting by her sister on the bank.',\n",
    "  'example2':\n",
    "      'Buda-Pesth seems a wonderful place.',\n",
    "  'example3':\n",
    "      'Scepticism was as much the result of knowledge, as knowledge is of scepticism.', \n",
    "  'example4':\n",
    "      \"Life \\\\\"out there\\\\\" is so strange, so unique, so full of hardship and danger, and yet so intensely interesting that it seems like another world.\"\n",
    "};\n",
    "\n",
    "function status(statusText) {\n",
    "  console.log(statusText);\n",
    "  document.getElementById('status').textContent = statusText;\n",
    "}\n",
    "\n",
    "function showMetadata(metadataJSON) {\n",
    "  document.getElementById('vocabularySize').textContent =\n",
    "      metadataJSON['vocabulary_size'];\n",
    "  document.getElementById('maxLen').textContent =\n",
    "      metadataJSON['max_len'];\n",
    "}\n",
    "\n",
    "function settextField(text, predict) {\n",
    "  const textField = document.getElementById('text-entry');\n",
    "  textField.value = text;\n",
    "  doPredict(predict);\n",
    "}\n",
    "\n",
    "function setPredictFunction(predict) {\n",
    "  const textField = document.getElementById('text-entry');\n",
    "  textField.addEventListener('input', () => doPredict(predict));\n",
    "}\n",
    "\n",
    "function disableLoadModelButtons() {\n",
    "  document.getElementById('load-model').style.display = 'none';\n",
    "}\n",
    "\n",
    "function doPredict(predict) {\n",
    "  const textField = document.getElementById('text-entry');\n",
    "  const result = predict(textField.value);\n",
    "  score_string = \"Class scores: \";\n",
    "  for (var x in result.score) {\n",
    "    score_string += x + \" ->  \" + result.score[x].toFixed(3) + \", \"\n",
    "  }\n",
    "  //console.log(score_string);\n",
    "  status(\n",
    "      score_string + ' elapsed: ' + result.elapsed.toFixed(3) + ' ms)');\n",
    "}\n",
    "\n",
    "function prepUI(predict) {\n",
    "  setPredictFunction(predict);\n",
    "  const testExampleSelect = document.getElementById('example-select');\n",
    "  testExampleSelect.addEventListener('change', () => {\n",
    "    settextField(examples[testExampleSelect.value], predict);\n",
    "  });\n",
    "  settextField(examples['example1'], predict);\n",
    "}\n",
    "\n",
    "async function urlExists(url) {\n",
    "  status('Testing url ' + url);\n",
    "  try {\n",
    "    const response = await fetch(url, {method: 'HEAD'});\n",
    "    return response.ok;\n",
    "  } catch (err) {\n",
    "    return false;\n",
    "  }\n",
    "}\n",
    "\n",
    "async function loadHostedPretrainedModel(url) {\n",
    "  status('Loading pretrained model from ' + url);\n",
    "  try {\n",
    "    const model = await tf.loadModel(url);\n",
    "    status('Done loading pretrained model.');\n",
    "    disableLoadModelButtons();\n",
    "    return model;\n",
    "  } catch (err) {\n",
    "    console.error(err);\n",
    "    status('Loading pretrained model failed.');\n",
    "  }\n",
    "}\n",
    "\n",
    "async function loadHostedMetadata(url) {\n",
    "  status('Loading metadata from ' + url);\n",
    "  try {\n",
    "    const metadataJson = await fetch(url);\n",
    "    const metadata = await metadataJson.json();\n",
    "    status('Done loading metadata.');\n",
    "    return metadata;\n",
    "  } catch (err) {\n",
    "    console.error(err);\n",
    "    status('Loading metadata failed.');\n",
    "  }\n",
    "}\n",
    "\n",
    "class Classifier {\n",
    "\n",
    "  async init(urls) {\n",
    "    this.urls = urls;\n",
    "    this.model = await loadHostedPretrainedModel(urls.model);\n",
    "    await this.loadMetadata();\n",
    "    return this;\n",
    "  }\n",
    "\n",
    "  async loadMetadata() {\n",
    "    const metadata =\n",
    "        await loadHostedMetadata(this.urls.metadata);\n",
    "    showMetadata(metadata);\n",
    "    this.maxLen = metadata['max_len'];\n",
    "    console.log('maxLen = ' + this.maxLen);\n",
    "    this.wordIndex = metadata['word_index']\n",
    "  }\n",
    "\n",
    "  predict(text) {\n",
    "    // Convert to lower case and remove all punctuations.\n",
    "    const inputText =\n",
    "        text.trim().toLowerCase().replace(/(\\.|\\,|\\!)/g, '').split(' ');\n",
    "    // Look up word indices.\n",
    "    const inputBuffer = tf.buffer([1, this.maxLen], 'float32');\n",
    "    for (let i = 0; i < inputText.length; ++i) {\n",
    "      const word = inputText[i];\n",
    "      inputBuffer.set(this.wordIndex[word], 0, i);\n",
    "      //console.log(word, this.wordIndex[word], inputBuffer);\n",
    "    }\n",
    "    const input = inputBuffer.toTensor();\n",
    "    //console.log(input);\n",
    "\n",
    "    status('Running inference');\n",
    "    const beginMs = performance.now();\n",
    "    const predictOut = this.model.predict(input);\n",
    "    //console.log(predictOut.dataSync());\n",
    "    const score = predictOut.dataSync();//[0];\n",
    "    predictOut.dispose();\n",
    "    const endMs = performance.now();\n",
    "\n",
    "    return {score: score, elapsed: (endMs - beginMs)};\n",
    "  }\n",
    "};\n",
    "\n",
    "async function setup() {\n",
    "  if (await urlExists(HOSTED_URLS.model)) {\n",
    "    status('Model available: ' + HOSTED_URLS.model);\n",
    "    const button = document.getElementById('load-model');\n",
    "    button.addEventListener('click', async () => {\n",
    "      const predictor = await new Classifier().init(HOSTED_URLS);\n",
    "      prepUI(x => predictor.predict(x));\n",
    "    });\n",
    "    button.style.display = 'inline-block';\n",
    "  }\n",
    "\n",
    "  status('Standing by.');\n",
    "}\n",
    "\n",
    "setup();\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KbvVVh1rkmga"
   },
   "outputs": [],
   "source": [
    "with open('index.html','w') as f:\n",
    "  f.write(index_html)\n",
    "  \n",
    "with open('index.js','w') as f:\n",
    "  f.write(index_js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0YtvaoazkuRT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/apple/Dropbox/Billy/ADL/HW4/pinhao1994.github.io/ADL/a4\n",
      "index.html index.js   \u001b[1m\u001b[36mmodel_js\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z3NX9FVLiBO7"
   },
   "source": [
    "Commit and push everything. Note: we're storing large binary files in GitHub, this isn't ideal (if you want to deploy a model down the road, better to host it in a cloud storage bucket)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RoL5aoRUh5DB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 361e924] fix example 4 str problem\n",
      " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
      "Enumerating objects: 9, done.\n",
      "Counting objects: 100% (9/9), done.\n",
      "Delta compression using up to 4 threads\n",
      "Compressing objects: 100% (5/5), done.\n",
      "Writing objects: 100% (5/5), 537 bytes | 537.00 KiB/s, done.\n",
      "Total 5 (delta 1), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
      "To https://github.com/pinhao1994/pinhao1994.github.io/\n",
      "   59b930d..361e924  master -> master\n"
     ]
    }
   ],
   "source": [
    "!git add . \n",
    "!git commit -m \"fix example 4 str problem\"\n",
    "!git push https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{USER_NAME}.github.io/ master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WDoo_fDVic2E"
   },
   "source": [
    "All done! Hopefully everything worked. You may need to wait a few moments for the changes to appear in your site. If not working, check the JavaScript console for errors (in Chrome: View -> Developer -> JavaScript Console)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1V1QLCxlikOI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, visit https://pinhao1994.github.io/ADL/a4/\n"
     ]
    }
   ],
   "source": [
    "print(\"Now, visit https://%s.github.io/%s/\" % (USER_NAME, SITE_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mnN6zAHWqPnR"
   },
   "source": [
    "If you are debugging and Chrome is failing to pick up your changes, though you've verified they're present in your GitHub repo, see the second answer to: https://superuser.com/questions/89809/how-to-force-refresh-without-cache-in-google-chrome"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "8_colab_to_webpage.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "ADL",
   "language": "python",
   "name": "adl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
